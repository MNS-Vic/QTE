#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
äº‹ä»¶æ€»çº¿

ç»Ÿä¸€çš„äº‹ä»¶å‘å¸ƒã€è®¢é˜…å’Œåˆ†å‘æœºåˆ¶
"""

import time
import queue
import threading
import logging
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable, Union
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, Future

from .event_types import Event, EventType, EventPriority


@dataclass
class EventMetadata:
    """äº‹ä»¶å…ƒæ•°æ®"""
    event_id: str
    timestamp: datetime
    priority: EventPriority
    source: Optional[str] = None
    correlation_id: Optional[str] = None
    retry_count: int = 0
    max_retries: int = 3
    timeout: Optional[float] = None
    
    def should_retry(self) -> bool:
        """æ˜¯å¦åº”è¯¥é‡è¯•"""
        return self.retry_count < self.max_retries
    
    def increment_retry(self):
        """å¢åŠ é‡è¯•æ¬¡æ•°"""
        self.retry_count += 1


@dataclass
class EventRecord:
    """äº‹ä»¶è®°å½•"""
    event_id: str
    event_type: str
    event_data: Any
    metadata: EventMetadata
    created_at: datetime = field(default_factory=datetime.now)
    processed_count: int = 0
    error_count: int = 0
    last_processed: Optional[datetime] = None
    last_error: Optional[str] = None
    
    def mark_processed(self):
        """æ ‡è®°ä¸ºå·²å¤„ç†"""
        self.processed_count += 1
        self.last_processed = datetime.now()
    
    def mark_error(self, error_msg: str):
        """æ ‡è®°é”™è¯¯"""
        self.error_count += 1
        self.last_error = error_msg


class EventBus:
    """
    äº‹ä»¶æ€»çº¿
    
    æä¾›ç»Ÿä¸€çš„äº‹ä»¶å‘å¸ƒã€è®¢é˜…å’Œåˆ†å‘æœºåˆ¶
    """
    
    def __init__(self, max_queue_size: int = 10000, 
                 max_workers: int = 4,
                 enable_async: bool = True):
        """
        åˆå§‹åŒ–äº‹ä»¶æ€»çº¿
        
        Parameters
        ----------
        max_queue_size : int, optional
            æœ€å¤§é˜Ÿåˆ—å¤§å°, by default 10000
        max_workers : int, optional
            æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°, by default 4
        enable_async : bool, optional
            æ˜¯å¦å¯ç”¨å¼‚æ­¥å¤„ç†, by default True
        """
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # é…ç½®
        self.max_queue_size = max_queue_size
        self.max_workers = max_workers
        self.enable_async = enable_async
        
        # äº‹ä»¶é˜Ÿåˆ—ï¼ˆä¼˜å…ˆçº§é˜Ÿåˆ—ï¼‰
        self._event_queue = queue.PriorityQueue(maxsize=max_queue_size)
        
        # è®¢é˜…è€…ç®¡ç†
        self._subscribers: Dict[str, List[Callable]] = {}
        self._subscriber_metadata: Dict[str, Dict[str, Any]] = {}
        
        # äº‹ä»¶è®°å½•
        self._event_records: Dict[str, EventRecord] = {}
        self._max_records = 10000  # æœ€å¤§è®°å½•æ•°
        
        # çº¿ç¨‹æ§åˆ¶
        self._processing_thread = None
        self._stop_processing = threading.Event()
        self._pause_processing = threading.Event()
        self._pause_processing.set()  # å¼€å§‹æ—¶ä¸æš‚åœ
        
        # å¼‚æ­¥å¤„ç†å™¨
        self._executor = ThreadPoolExecutor(max_workers=max_workers) if enable_async else None
        self._async_futures: List[Future] = []
        
        # ç»Ÿè®¡ä¿¡æ¯
        self._stats = {
            'events_published': 0,
            'events_processed': 0,
            'events_failed': 0,
            'subscribers_count': 0,
            'processing_time_total': 0.0,
            'start_time': None
        }
        
        # çº¿ç¨‹å®‰å…¨é”
        self._lock = threading.Lock()
        
        self.logger.info("âœ… äº‹ä»¶æ€»çº¿åˆå§‹åŒ–å®Œæˆ")
    
    def start(self) -> bool:
        """
        å¯åŠ¨äº‹ä»¶æ€»çº¿
        
        Returns
        -------
        bool
            å¯åŠ¨æ˜¯å¦æˆåŠŸ
        """
        with self._lock:
            if self._processing_thread and self._processing_thread.is_alive():
                self.logger.warning("äº‹ä»¶æ€»çº¿å·²åœ¨è¿è¡Œ")
                return False
            
            self._stop_processing.clear()
            self._pause_processing.set()
            
            self._processing_thread = threading.Thread(
                target=self._processing_loop,
                name="EventBus_Processor"
            )
            self._processing_thread.daemon = True
            self._processing_thread.start()
            
            self._stats['start_time'] = time.time()
            
            self.logger.info("ğŸš€ äº‹ä»¶æ€»çº¿å·²å¯åŠ¨")
            return True
    
    def stop(self) -> bool:
        """
        åœæ­¢äº‹ä»¶æ€»çº¿
        
        Returns
        -------
        bool
            åœæ­¢æ˜¯å¦æˆåŠŸ
        """
        with self._lock:
            if not self._processing_thread or not self._processing_thread.is_alive():
                self.logger.info("äº‹ä»¶æ€»çº¿æœªè¿è¡Œ")
                return True
            
            self._stop_processing.set()
            self._pause_processing.set()
            
            # å‘é€åœæ­¢ä¿¡å·
            try:
                self._event_queue.put((0, time.time(), None), block=False)
            except queue.Full:
                self.logger.warning("äº‹ä»¶é˜Ÿåˆ—å·²æ»¡ï¼Œæ— æ³•å‘é€åœæ­¢ä¿¡å·")
            
            # ç­‰å¾…çº¿ç¨‹ç»“æŸ
            if self._processing_thread:
                self._processing_thread.join(timeout=5.0)
                if self._processing_thread.is_alive():
                    self.logger.warning("äº‹ä»¶å¤„ç†çº¿ç¨‹æœªåœ¨è¶…æ—¶å†…ç»“æŸ")
                else:
                    self.logger.info("âœ… äº‹ä»¶å¤„ç†çº¿ç¨‹å·²åœæ­¢")
            
            # å…³é—­å¼‚æ­¥æ‰§è¡Œå™¨
            if self._executor:
                self._executor.shutdown(wait=True)
            
            self._processing_thread = None
            
            self.logger.info("â¹ï¸ äº‹ä»¶æ€»çº¿å·²åœæ­¢")
            return True
    
    def pause(self) -> bool:
        """æš‚åœäº‹ä»¶å¤„ç†"""
        self._pause_processing.clear()
        self.logger.info("â¸ï¸ äº‹ä»¶å¤„ç†å·²æš‚åœ")
        return True
    
    def resume(self) -> bool:
        """æ¢å¤äº‹ä»¶å¤„ç†"""
        self._pause_processing.set()
        self.logger.info("â–¶ï¸ äº‹ä»¶å¤„ç†å·²æ¢å¤")
        return True
    
    def publish(self, event: Union[Event, str], 
                event_data: Any = None,
                priority: EventPriority = EventPriority.NORMAL,
                metadata: Optional[Dict[str, Any]] = None) -> str:
        """
        å‘å¸ƒäº‹ä»¶
        
        Parameters
        ----------
        event : Union[Event, str]
            äº‹ä»¶å¯¹è±¡æˆ–äº‹ä»¶ç±»å‹å­—ç¬¦ä¸²
        event_data : Any, optional
            äº‹ä»¶æ•°æ®ï¼ˆå½“eventä¸ºå­—ç¬¦ä¸²æ—¶ä½¿ç”¨ï¼‰
        priority : EventPriority, optional
            äº‹ä»¶ä¼˜å…ˆçº§, by default EventPriority.NORMAL
        metadata : Optional[Dict[str, Any]], optional
            é¢å¤–å…ƒæ•°æ®, by default None
            
        Returns
        -------
        str
            äº‹ä»¶ID
        """
        try:
            # å¤„ç†äº‹ä»¶å¯¹è±¡
            if isinstance(event, Event):
                event_obj = event
                event_type = event.event_type
                event_data = event
            else:
                event_type = event
                event_obj = Event(
                    event_type=event_type,
                    priority=priority,
                    metadata=metadata or {}
                )
            
            # åˆ›å»ºäº‹ä»¶å…ƒæ•°æ®
            event_metadata = EventMetadata(
                event_id=event_obj.event_id,
                timestamp=event_obj.timestamp,
                priority=priority,
                source=metadata.get('source') if metadata else None,
                correlation_id=metadata.get('correlation_id') if metadata else None
            )
            
            # åˆ›å»ºäº‹ä»¶è®°å½•
            event_record = EventRecord(
                event_id=event_obj.event_id,
                event_type=event_type,
                event_data=event_data or event_obj,
                metadata=event_metadata
            )
            
            # å­˜å‚¨äº‹ä»¶è®°å½•
            with self._lock:
                self._event_records[event_obj.event_id] = event_record
                self._cleanup_old_records()
                self._stats['events_published'] += 1
            
            # å°†äº‹ä»¶æ”¾å…¥é˜Ÿåˆ—ï¼ˆä¼˜å…ˆçº§å€¼è¶Šå°ï¼Œä¼˜å…ˆçº§è¶Šé«˜ï¼‰
            priority_value = priority.value
            try:
                self._event_queue.put((priority_value, time.time(), event_record), block=False)
            except queue.Full:
                self.logger.error("äº‹ä»¶é˜Ÿåˆ—å·²æ»¡ï¼Œæ— æ³•å‘å¸ƒäº‹ä»¶")
                return ""
            
            self.logger.debug(f"ğŸ“¤ äº‹ä»¶å·²å‘å¸ƒ: {event_type} [{event_obj.event_id}]")
            return event_obj.event_id
            
        except Exception as e:
            self.logger.error(f"å‘å¸ƒäº‹ä»¶å¤±è´¥: {e}")
            return ""
    
    def subscribe(self, event_type: str, 
                  handler: Callable[[Any, EventMetadata], None],
                  priority: EventPriority = EventPriority.NORMAL,
                  async_handler: bool = False) -> str:
        """
        è®¢é˜…äº‹ä»¶
        
        Parameters
        ----------
        event_type : str
            äº‹ä»¶ç±»å‹
        handler : Callable[[Any, EventMetadata], None]
            äº‹ä»¶å¤„ç†å‡½æ•°
        priority : EventPriority, optional
            å¤„ç†å™¨ä¼˜å…ˆçº§, by default EventPriority.NORMAL
        async_handler : bool, optional
            æ˜¯å¦å¼‚æ­¥å¤„ç†, by default False
            
        Returns
        -------
        str
            è®¢é˜…ID
        """
        try:
            subscription_id = str(uuid.uuid4())[:8]
            
            with self._lock:
                if event_type not in self._subscribers:
                    self._subscribers[event_type] = []
                
                self._subscribers[event_type].append(handler)
                
                # å­˜å‚¨è®¢é˜…å…ƒæ•°æ®
                self._subscriber_metadata[subscription_id] = {
                    'event_type': event_type,
                    'handler': handler,
                    'priority': priority,
                    'async_handler': async_handler,
                    'created_at': datetime.now(),
                    'call_count': 0,
                    'error_count': 0
                }
                
                self._stats['subscribers_count'] = len(self._subscriber_metadata)
            
            handler_name = getattr(handler, '__name__', str(handler))
            self.logger.debug(f"âœ… å·²è®¢é˜…äº‹ä»¶: {event_type} -> {handler_name} [{subscription_id}]")
            
            return subscription_id
            
        except Exception as e:
            self.logger.error(f"è®¢é˜…äº‹ä»¶å¤±è´¥: {e}")
            return ""
    
    def unsubscribe(self, subscription_id: str) -> bool:
        """
        å–æ¶ˆè®¢é˜…
        
        Parameters
        ----------
        subscription_id : str
            è®¢é˜…ID
            
        Returns
        -------
        bool
            å–æ¶ˆæ˜¯å¦æˆåŠŸ
        """
        try:
            with self._lock:
                if subscription_id not in self._subscriber_metadata:
                    self.logger.warning(f"è®¢é˜…IDä¸å­˜åœ¨: {subscription_id}")
                    return False
                
                metadata = self._subscriber_metadata[subscription_id]
                event_type = metadata['event_type']
                handler = metadata['handler']
                
                # ä»è®¢é˜…åˆ—è¡¨ä¸­ç§»é™¤
                if event_type in self._subscribers and handler in self._subscribers[event_type]:
                    self._subscribers[event_type].remove(handler)
                    
                    # å¦‚æœè¯¥äº‹ä»¶ç±»å‹æ²¡æœ‰è®¢é˜…è€…äº†ï¼Œåˆ é™¤é”®
                    if not self._subscribers[event_type]:
                        del self._subscribers[event_type]
                
                # åˆ é™¤å…ƒæ•°æ®
                del self._subscriber_metadata[subscription_id]
                self._stats['subscribers_count'] = len(self._subscriber_metadata)
            
            self.logger.debug(f"âœ… å·²å–æ¶ˆè®¢é˜…: {subscription_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"å–æ¶ˆè®¢é˜…å¤±è´¥: {e}")
            return False
    
    def get_queue_size(self) -> int:
        """è·å–äº‹ä»¶é˜Ÿåˆ—å¤§å°"""
        return self._event_queue.qsize()
    
    def get_subscriber_count(self) -> int:
        """è·å–è®¢é˜…è€…æ•°é‡"""
        with self._lock:
            return len(self._subscriber_metadata)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self._lock:
            stats = self._stats.copy()
            stats['queue_size'] = self.get_queue_size()
            stats['subscriber_count'] = self.get_subscriber_count()
            
            # è®¡ç®—è¿è¡Œæ—¶é—´
            if stats['start_time']:
                stats['uptime'] = time.time() - stats['start_time']
                
                # è®¡ç®—å¹³å‡å¤„ç†æ—¶é—´
                if stats['events_processed'] > 0:
                    stats['avg_processing_time'] = stats['processing_time_total'] / stats['events_processed']
                else:
                    stats['avg_processing_time'] = 0.0
            
            return stats
    
    def _processing_loop(self):
        """äº‹ä»¶å¤„ç†å¾ªç¯"""
        self.logger.info("ğŸš€ äº‹ä»¶å¤„ç†çº¿ç¨‹å¯åŠ¨")
        
        processed_count = 0
        
        while not self._stop_processing.is_set():
            try:
                # ç­‰å¾…æ¢å¤ï¼ˆå¦‚æœæš‚åœï¼‰
                if not self._pause_processing.wait(timeout=0.1):
                    continue
                
                # è·å–äº‹ä»¶
                try:
                    priority, timestamp, event_record = self._event_queue.get(block=True, timeout=0.1)
                except queue.Empty:
                    continue
                
                # æ£€æŸ¥åœæ­¢ä¿¡å·
                if event_record is None or self._stop_processing.is_set():
                    break
                
                # å¤„ç†äº‹ä»¶
                start_time = time.time()
                success = self._process_event(event_record)
                processing_time = time.time() - start_time
                
                # æ›´æ–°ç»Ÿè®¡
                with self._lock:
                    if success:
                        self._stats['events_processed'] += 1
                        event_record.mark_processed()
                    else:
                        self._stats['events_failed'] += 1
                    
                    self._stats['processing_time_total'] += processing_time
                
                processed_count += 1
                
                # æ ‡è®°ä»»åŠ¡å®Œæˆ
                self._event_queue.task_done()
                
            except Exception as e:
                self.logger.error(f"äº‹ä»¶å¤„ç†å¾ªç¯å¼‚å¸¸: {e}", exc_info=True)
        
        self.logger.info(f"ğŸ äº‹ä»¶å¤„ç†çº¿ç¨‹ç»“æŸï¼Œå¤„ç†äº‹ä»¶æ•°: {processed_count}")
    
    def _process_event(self, event_record: EventRecord) -> bool:
        """å¤„ç†å•ä¸ªäº‹ä»¶"""
        try:
            event_type = event_record.event_type
            event_data = event_record.event_data
            metadata = event_record.metadata
            
            # è·å–è®¢é˜…è€…
            handlers = []
            with self._lock:
                if event_type in self._subscribers:
                    handlers.extend(self._subscribers[event_type])
                
                # é€šé…ç¬¦è®¢é˜…è€…
                if "*" in self._subscribers:
                    handlers.extend(self._subscribers["*"])
            
            if not handlers:
                return True  # æ²¡æœ‰å¤„ç†å™¨ä¸ç®—å¤±è´¥
            
            # æ‰§è¡Œå¤„ç†å™¨
            success_count = 0
            for handler in handlers:
                try:
                    # æŸ¥æ‰¾å¤„ç†å™¨å…ƒæ•°æ®
                    handler_metadata = None
                    for sub_id, meta in self._subscriber_metadata.items():
                        if meta['handler'] == handler:
                            handler_metadata = meta
                            break
                    
                    # æ‰§è¡Œå¤„ç†å™¨
                    if handler_metadata and handler_metadata.get('async_handler') and self._executor:
                        # å¼‚æ­¥æ‰§è¡Œ
                        future = self._executor.submit(handler, event_data, metadata)
                        self._async_futures.append(future)
                        
                        # æ¸…ç†å·²å®Œæˆçš„future
                        self._async_futures = [f for f in self._async_futures if not f.done()]
                    else:
                        # åŒæ­¥æ‰§è¡Œ
                        handler(event_data, metadata)
                    
                    success_count += 1
                    
                    # æ›´æ–°å¤„ç†å™¨ç»Ÿè®¡
                    if handler_metadata:
                        handler_metadata['call_count'] += 1
                    
                except Exception as e:
                    handler_name = getattr(handler, '__name__', str(handler))
                    self.logger.error(f"å¤„ç†å™¨ {handler_name} å¤„ç†äº‹ä»¶ {event_type} æ—¶å‡ºé”™: {e}")
                    
                    # æ›´æ–°é”™è¯¯ç»Ÿè®¡
                    if handler_metadata:
                        handler_metadata['error_count'] += 1
                    
                    event_record.mark_error(str(e))
            
            return success_count > 0
            
        except Exception as e:
            self.logger.error(f"å¤„ç†äº‹ä»¶å¤±è´¥: {e}", exc_info=True)
            return False
    
    def _cleanup_old_records(self):
        """æ¸…ç†æ—§çš„äº‹ä»¶è®°å½•"""
        if len(self._event_records) > self._max_records:
            # ä¿ç•™æœ€æ–°çš„è®°å½•
            sorted_records = sorted(
                self._event_records.items(),
                key=lambda x: x[1].created_at,
                reverse=True
            )
            
            # ä¿ç•™æœ€æ–°çš„80%è®°å½•
            keep_count = int(self._max_records * 0.8)
            records_to_keep = dict(sorted_records[:keep_count])
            
            self._event_records = records_to_keep
            self.logger.debug(f"æ¸…ç†äº‹ä»¶è®°å½•ï¼Œä¿ç•™ {keep_count} æ¡è®°å½•")
