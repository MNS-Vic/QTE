#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç»Ÿä¸€å¼•æ“æ€§èƒ½åŸºå‡†æµ‹è¯•

æµ‹è¯•V1/V2æ¶æ„ç»Ÿä¸€åçš„æ€§èƒ½è¡¨ç°å’Œå¯¹æ¯”
"""

import time
import pytest
import pandas as pd
import numpy as np
from typing import Dict, List, Any
from datetime import datetime, timedelta

# å¯¼å…¥ç»Ÿä¸€æ¶æ„å¼•æ“
try:
    from qte.core.engines import (
        UnifiedVectorEngine, VectorEngineV2, VectorEngineV1Compat,
        create_engine
    )
    _UNIFIED_ENGINES_AVAILABLE = True
    print("âœ… ç»Ÿä¸€å¼•æ“æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    _UNIFIED_ENGINES_AVAILABLE = False
    print(f"âŒ ç»Ÿä¸€å¼•æ“æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")


class SimpleStrategy:
    """ç®€å•æµ‹è¯•ç­–ç•¥"""
    
    def __init__(self, short_window: int = 10, long_window: int = 30):
        self.short_window = short_window
        self.long_window = long_window
    
    def generate_signals(self, data: pd.DataFrame) -> pd.DataFrame:
        """ç”Ÿæˆäº¤æ˜“ä¿¡å·"""
        signals = data.copy()
        
        # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
        signals['short_ma'] = signals['close'].rolling(window=self.short_window).mean()
        signals['long_ma'] = signals['close'].rolling(window=self.long_window).mean()
        
        # ç”Ÿæˆä¿¡å·
        signals['signal'] = 0
        signals.loc[signals['short_ma'] > signals['long_ma'], 'signal'] = 1
        signals.loc[signals['short_ma'] < signals['long_ma'], 'signal'] = -1
        
        return signals


def create_test_data(size: int, seed: int = 42) -> pd.DataFrame:
    """åˆ›å»ºæµ‹è¯•æ•°æ®"""
    np.random.seed(seed)
    
    # ç”Ÿæˆæ—¥æœŸåºåˆ—
    start_date = datetime(2020, 1, 1)
    dates = [start_date + timedelta(days=i) for i in range(size)]
    
    # ç”Ÿæˆä»·æ ¼æ•°æ®
    returns = np.random.normal(0.001, 0.02, size)
    prices = 100 * np.exp(np.cumsum(returns))
    
    # åˆ›å»ºOHLCVæ•°æ®
    data = pd.DataFrame({
        'datetime': dates,
        'open': prices * (1 + np.random.normal(0, 0.001, size)),
        'high': prices * (1 + np.abs(np.random.normal(0, 0.005, size))),
        'low': prices * (1 - np.abs(np.random.normal(0, 0.005, size))),
        'close': prices,
        'volume': np.random.randint(1000, 10000, size)
    })
    
    return data


def measure_engine_performance(engine_factory, data_size: int, iterations: int = 3) -> Dict[str, Any]:
    """
    æµ‹é‡å¼•æ“æ€§èƒ½
    
    Parameters
    ----------
    engine_factory : callable
        å¼•æ“åˆ›å»ºå‡½æ•°
    data_size : int
        æ•°æ®å¤§å°
    iterations : int
        è¿­ä»£æ¬¡æ•°
        
    Returns
    -------
    Dict[str, Any]
        æ€§èƒ½æµ‹è¯•ç»“æœ
    """
    times = []
    success_count = 0
    errors = []
    
    for i in range(iterations):
        try:
            # åˆ›å»ºæµ‹è¯•æ•°æ®å’Œç­–ç•¥
            data = create_test_data(data_size, seed=42 + i)
            strategy = SimpleStrategy()
            
            # åˆ›å»ºå¼•æ“
            engine = engine_factory()
            
            # é…ç½®å¼•æ“
            if hasattr(engine, 'initialize'):
                if 'V1Compat' in str(type(engine)):
                    engine.initialize(100000, 0.001)
                else:
                    engine.initialize({
                        'initial_capital': 100000,
                        'commission_rate': 0.001
                    })
            
            # æµ‹é‡æ‰§è¡Œæ—¶é—´
            start_time = time.time()
            
            # è®¾ç½®æ•°æ®å’Œç­–ç•¥
            engine.set_data(data)
            engine.add_strategy(strategy)
            
            # è¿è¡Œå›æµ‹
            result = engine.run_backtest()
            
            end_time = time.time()
            execution_time = end_time - start_time
            
            # æ£€æŸ¥ç»“æœ
            if hasattr(result, 'success'):
                success = result.success
            else:
                success = result.get('success', False)
            
            if success:
                times.append(execution_time)
                success_count += 1
            else:
                errors.append(f"Iteration {i}: å›æµ‹å¤±è´¥")
            
            # æ¸…ç†èµ„æº
            if hasattr(engine, 'cleanup'):
                engine.cleanup()
                
        except Exception as e:
            errors.append(f"Iteration {i}: {str(e)}")
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    if times:
        avg_time = np.mean(times)
        min_time = np.min(times)
        max_time = np.max(times)
        std_time = np.std(times)
        throughput = data_size / avg_time
    else:
        avg_time = min_time = max_time = std_time = throughput = 0
    
    return {
        'data_size': data_size,
        'iterations': iterations,
        'success_count': success_count,
        'success_rate': success_count / iterations if iterations > 0 else 0,
        'avg_time': avg_time,
        'min_time': min_time,
        'max_time': max_time,
        'std_time': std_time,
        'throughput': throughput,
        'errors': errors
    }


@pytest.mark.performance
@pytest.mark.skipif(not _UNIFIED_ENGINES_AVAILABLE, reason="ç»Ÿä¸€å¼•æ“æ¨¡å—ä¸å¯ç”¨")
class TestUnifiedEnginePerformance:
    """ç»Ÿä¸€å¼•æ“æ€§èƒ½æµ‹è¯•ç±»"""
    
    def test_unified_engine_basic_performance(self):
        """æµ‹è¯•ç»Ÿä¸€å¼•æ“åŸºæœ¬æ€§èƒ½"""
        engine_factory = lambda: UnifiedVectorEngine(compatibility_mode='auto')
        result = measure_engine_performance(engine_factory, 500, 2)
        
        # éªŒè¯æ€§èƒ½æŒ‡æ ‡
        assert result['success_rate'] >= 0.5, "æˆåŠŸç‡è¿‡ä½"
        assert result['avg_time'] < 10.0, "æ‰§è¡Œæ—¶é—´è¿‡é•¿"
        assert result['throughput'] > 50, "ååé‡è¿‡ä½"
    
    def test_compatibility_modes_performance(self):
        """æµ‹è¯•ä¸åŒå…¼å®¹æ€§æ¨¡å¼çš„æ€§èƒ½"""
        modes = ['auto', 'v1', 'v2', 'hybrid']
        results = {}
        
        for mode in modes:
            engine_factory = lambda m=mode: UnifiedVectorEngine(compatibility_mode=m)
            result = measure_engine_performance(engine_factory, 300, 1)
            results[mode] = result
            
            # åŸºæœ¬æ€§èƒ½è¦æ±‚
            assert result['success_rate'] > 0, f"æ¨¡å¼ {mode} å®Œå…¨å¤±è´¥"
            assert result['avg_time'] < 15.0, f"æ¨¡å¼ {mode} æ‰§è¡Œæ—¶é—´è¿‡é•¿"
        
        # æ‰“å°æ€§èƒ½å¯¹æ¯”
        print("\nå…¼å®¹æ€§æ¨¡å¼æ€§èƒ½å¯¹æ¯”:")
        for mode, result in results.items():
            print(f"  {mode}: {result['avg_time']:.3f}s, ååé‡: {result['throughput']:.0f} è¡Œ/ç§’")
    
    def test_engine_comparison(self):
        """æµ‹è¯•ä¸åŒå¼•æ“çš„æ€§èƒ½å¯¹æ¯”"""
        engines = {
            'UnifiedAuto': lambda: UnifiedVectorEngine(compatibility_mode='auto'),
            'UnifiedV2': lambda: UnifiedVectorEngine(compatibility_mode='v2'),
            'V2Direct': lambda: VectorEngineV2(),
            'V1Compat': lambda: VectorEngineV1Compat(),
        }
        
        data_size = 1000
        results = {}
        
        for name, factory in engines.items():
            result = measure_engine_performance(factory, data_size, 1)
            results[name] = result
            
            # åŸºæœ¬è¦æ±‚
            assert result['success_rate'] > 0, f"å¼•æ“ {name} å®Œå…¨å¤±è´¥"
        
        # æ€§èƒ½å¯¹æ¯”åˆ†æ
        print(f"\nå¼•æ“æ€§èƒ½å¯¹æ¯” (æ•°æ®å¤§å°: {data_size}):")
        sorted_results = sorted(results.items(), key=lambda x: x[1]['avg_time'])
        
        for i, (name, result) in enumerate(sorted_results, 1):
            print(f"  {i}. {name}: {result['avg_time']:.3f}s, "
                  f"ååé‡: {result['throughput']:.0f} è¡Œ/ç§’, "
                  f"æˆåŠŸç‡: {result['success_rate']:.1%}")
    
    def test_scalability(self):
        """æµ‹è¯•å¯æ‰©å±•æ€§"""
        data_sizes = [100, 500, 1000, 2000]
        engine_factory = lambda: UnifiedVectorEngine(compatibility_mode='auto')
        
        results = []
        for size in data_sizes:
            result = measure_engine_performance(engine_factory, size, 1)
            results.append((size, result))
            
            # åŸºæœ¬è¦æ±‚
            assert result['success_rate'] > 0, f"æ•°æ®å¤§å° {size} æµ‹è¯•å¤±è´¥"
            assert result['avg_time'] < size * 0.01, f"æ•°æ®å¤§å° {size} æ€§èƒ½è¿‡å·®"  # 100è¡Œ/ç§’æœ€ä½è¦æ±‚
        
        # åˆ†æå¯æ‰©å±•æ€§
        print("\nå¯æ‰©å±•æ€§æµ‹è¯•ç»“æœ:")
        for size, result in results:
            print(f"  {size} è¡Œ: {result['avg_time']:.3f}s, "
                  f"ååé‡: {result['throughput']:.0f} è¡Œ/ç§’")
    
    def test_factory_performance(self):
        """æµ‹è¯•å¼•æ“å·¥å‚æ€§èƒ½"""
        factory_configs = [
            ('auto', {}),
            ('unified', {'compatibility_mode': 'auto'}),
            ('v2', {'high_performance': True}),
            ('v1', {'legacy_mode': True}),
        ]
        
        for engine_type, config in factory_configs:
            engine_factory = lambda: create_engine(engine_type, config)
            result = measure_engine_performance(engine_factory, 200, 1)
            
            # éªŒè¯å·¥å‚åˆ›å»ºçš„å¼•æ“æ€§èƒ½
            assert result['success_rate'] > 0, f"å·¥å‚å¼•æ“ {engine_type} å¤±è´¥"
            assert result['avg_time'] < 5.0, f"å·¥å‚å¼•æ“ {engine_type} æ€§èƒ½è¿‡å·®"
            
            print(f"å·¥å‚å¼•æ“ {engine_type}: {result['avg_time']:.3f}s")
    
    def test_memory_usage(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # åˆ›å»ºå¤šä¸ªå¼•æ“å®ä¾‹
        engines = []
        for i in range(5):
            engine = UnifiedVectorEngine(compatibility_mode='auto')
            engine.initialize({'initial_capital': 100000})
            engines.append(engine)
        
        # è¿è¡Œä¸€äº›æ“ä½œ
        data = create_test_data(500)
        strategy = SimpleStrategy()
        
        for engine in engines:
            engine.set_data(data)
            engine.add_strategy(strategy)
        
        current_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = current_memory - initial_memory
        
        # æ¸…ç†
        for engine in engines:
            if hasattr(engine, 'cleanup'):
                engine.cleanup()
        
        print(f"å†…å­˜ä½¿ç”¨æµ‹è¯•: åˆå§‹ {initial_memory:.1f}MB, "
              f"å³°å€¼ {current_memory:.1f}MB, "
              f"å¢åŠ  {memory_increase:.1f}MB")
        
        # å†…å­˜ä½¿ç”¨ä¸åº”è¯¥è¿‡é«˜
        assert memory_increase < 100, "å†…å­˜ä½¿ç”¨è¿‡é«˜"
    
    def test_concurrent_performance(self):
        """æµ‹è¯•å¹¶å‘æ€§èƒ½"""
        import threading
        import queue
        
        results_queue = queue.Queue()
        
        def run_engine_test():
            try:
                engine = UnifiedVectorEngine(compatibility_mode='auto')
                engine.initialize({'initial_capital': 100000})
                
                data = create_test_data(200)
                strategy = SimpleStrategy()
                
                start_time = time.time()
                engine.set_data(data)
                engine.add_strategy(strategy)
                result = engine.run_backtest()
                end_time = time.time()
                
                success = result.success if hasattr(result, 'success') else result.get('success', False)
                results_queue.put({
                    'success': success,
                    'time': end_time - start_time
                })
                
                if hasattr(engine, 'cleanup'):
                    engine.cleanup()
                    
            except Exception as e:
                results_queue.put({'error': str(e)})
        
        # å¯åŠ¨å¤šä¸ªçº¿ç¨‹
        threads = []
        for i in range(3):
            thread = threading.Thread(target=run_engine_test)
            threads.append(thread)
            thread.start()
        
        # ç­‰å¾…æ‰€æœ‰çº¿ç¨‹å®Œæˆ
        for thread in threads:
            thread.join()
        
        # æ”¶é›†ç»“æœ
        results = []
        while not results_queue.empty():
            results.append(results_queue.get())
        
        # éªŒè¯å¹¶å‘æ€§èƒ½
        success_count = sum(1 for r in results if r.get('success', False))
        error_count = sum(1 for r in results if 'error' in r)
        
        print(f"å¹¶å‘æµ‹è¯•ç»“æœ: æˆåŠŸ {success_count}, é”™è¯¯ {error_count}")
        
        assert success_count >= 2, "å¹¶å‘æµ‹è¯•æˆåŠŸç‡è¿‡ä½"
        assert error_count <= 1, "å¹¶å‘æµ‹è¯•é”™è¯¯è¿‡å¤š"


def main():
    """è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    if not _UNIFIED_ENGINES_AVAILABLE:
        print("âŒ ç»Ÿä¸€å¼•æ“æ¨¡å—ä¸å¯ç”¨ï¼Œè·³è¿‡æ€§èƒ½æµ‹è¯•")
        return
    
    print("ğŸš€ å¼€å§‹ç»Ÿä¸€å¼•æ“æ€§èƒ½åŸºå‡†æµ‹è¯•")
    print("=" * 50)
    
    # è¿è¡ŒåŸºæœ¬æ€§èƒ½æµ‹è¯•
    print("\n1. åŸºæœ¬æ€§èƒ½æµ‹è¯•")
    engine_factory = lambda: UnifiedVectorEngine(compatibility_mode='auto')
    result = measure_engine_performance(engine_factory, 1000, 3)
    
    print(f"å¹³å‡æ—¶é—´: {result['avg_time']:.3f}s")
    print(f"ååé‡: {result['throughput']:.0f} è¡Œ/ç§’")
    print(f"æˆåŠŸç‡: {result['success_rate']:.1%}")
    
    # å¼•æ“å¯¹æ¯”æµ‹è¯•
    print("\n2. å¼•æ“å¯¹æ¯”æµ‹è¯•")
    engines = {
        'UnifiedAuto': lambda: UnifiedVectorEngine(compatibility_mode='auto'),
        'V2Engine': lambda: VectorEngineV2(),
        'V1Compat': lambda: VectorEngineV1Compat(),
    }
    
    for name, factory in engines.items():
        result = measure_engine_performance(factory, 500, 1)
        print(f"{name}: {result['avg_time']:.3f}s, {result['throughput']:.0f} è¡Œ/ç§’")
    
    print("\nğŸ‰ æ€§èƒ½åŸºå‡†æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()
